<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <title>AI在假新聞判別的運用</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <script>
        $(document).ready(function () {
            $('a[href^="#"]').on('click', function (e) {
                e.preventDefault();

                var target = this.hash;
                var $target = $(target);

                $('html, body').stop().animate({
                    'scrollTop': $target.offset().top
                }, 900, 'swing', function () {
                    window.location.hash = target;
                });
            });
        });
        document.addEventListener("DOMContentLoaded", function () {
            var nav = document.querySelector("nav");
            var lastScrollTop = 0;

            window.addEventListener("scroll", function () {
                var currentScrollTop = window.scrollY;

                if (currentScrollTop > lastScrollTop) {
                    // 向下滾動
                    nav.classList.add("scroll-up");
                } else {
                    // 向上滾動
                    nav.classList.remove("scroll-up");
                }

                lastScrollTop = currentScrollTop;
            });
        });

        var prevScrollpos = window.pageYOffset;

        window.onscroll = function () {
            var currentScrollPos = window.pageYOffset;

            if (prevScrollpos > currentScrollPos) {
                document.getElementById("navbar").classList.add("fixed");
                document.getElementById("navbar").classList.remove("absolute");
            } else {
                document.getElementById("navbar").classList.remove("fixed");
                document.getElementById("navbar").classList.add("absolute");
            }

            prevScrollpos = currentScrollPos;
        }

        /* 以下幾行若新增，可讓導覽列在網頁沒有捲動時展開。 */
        /*var timeout = null;
        window.addEventListener('scroll', function () {
            clearTimeout(timeout);
            timeout = setTimeout(function () {
                document.getElementsByTagName("nav")[0].classList.remove("hide");
            }, 250);
        });*/
    </script>
</head>

<body>
    <nav id="navbar">
        <nav class="navbar navbar-expand-lg navbar-light bg-light sticky-top">
            <a class="navbar-brand" href="#"><strong>AI 在假新聞判別的運用</strong></a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse justify-content-end" id="navbarNav">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="#background">Background</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#transformer-model">Transformer Model</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#example">Example</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#reference">Reference</a>
                    </li>
                </ul>
            </div>
        </nav>
    </nav>
    <header>
        <div class="title">
            <h1><b>AI 在假新聞判別的運用</b></h1>
            <h2>The application of AI<br>in the detection of fake news</h2>
            <h3>Group 5</h3>
            <h4>資管一</h4>
            <h5>萬亭妤 李元中 李謙謙 陳詠旭</h5>
        </div>
    </header>
    <main>
        <section class="content">
            <section id="background">
                <h3>Background</h3>
                <hr>
                <p><b>假新聞是指故意捏造、篡改或散播虛假信息的新聞。</b>產生的主要因素包括：網路傳播的普及、社交媒體的興起、點擊率和廣告收入、政治或經濟動機。<br>
                    解決假新聞問題需要綜合多方面的努力，包括：技術手段、教育提升媒體素養，以及社會對真實性的關注。<br>
                    假新聞與人工智慧（AI）之間存在一定的相互影響， AI 也被應用於檢測和對抗假新聞。<br>
                    機器學習算法可以分析大量數據，辨識模式，並識別可能的虛假信息。然而這場「技術戰爭」也在不斷升級，假新聞製作技巧不斷進步，迫使檢測方法不斷更新。</p>
            </section>
            <section id="transformer-model">
                <h3>Transformer Model</h3>
                <hr>
                <p>Transformer模型由多個模塊組成，每個模塊都有著特定的功能，並共同協作以理解文本並生成下一個單詞。以下是這些模塊的簡要介紹：</p>
                <div class="container">
                    <div class="left">
                        <ul>
                            <li><b>Tokenization（分詞）：</b>將文本中的字詞轉化為標記（tokens），以便模型能夠處理和理解它們。</li>
                            <li><b>Embedding（嵌入）：</b>將標記轉化為數字（向量）表示形式，使得模型可以對其進行計算和處理。嵌入將每個標記映射到一個高維向量空間中，捕捉字詞之間的語義關係。
                            </li>
                            <li><b>Positional
                                    encoding（位置編碼）：</b>為文本中的每個字詞添加順序信息，解決單詞順序對於模型的重要性。通過位置編碼，模型能夠區分不同單詞在向子中的位置，從而更好地理解上下文關係。
                            </li>
                            <li><b>Transformer block（變換器塊）：</b>是 Transformer 模型的核心組件，由一個注意力塊和一個前饋塊組成。</li>
                            <li><b>Attention（注意力塊）：</b>用於為文本添加上下文內容，捕捉不同單詞之間的依賴關係。</li>
                            <li><b>Feedforward（前饋網絡）：</b>則用於對注意力塊的輸出進行進一步的非線性變換，以產生對下一個單詞的預測。</li>
                            <li><b>Softmax（歸一層）：</b>將模型預測的分數轉化為概率分布，以便進行下一個字詞的採樣。通過對分數進行歸一化，Softmax
                                層將其轉化為概率值，使得模型能夠選擇概率最高的單詞作為預測輸出。
                            </li>
                        </ul>
                        <p><b>Attention 為模型的核心</b>，它的主要功能為判斷每個詞在段落中的意思。同一個詞可能有不同的含意，像是 bank 有銀行和河堤的意思，這個情況 Attention
                            就能幫助模型從上下文中判斷是何意義。而 Transformer 中使用的為多頭注意力（Multi-Head
                            Attention），它使用了多種不同的嵌入去修改向量並添加上下文。簡單來說就是同時有多個注意力執行，並將結果合併起來。</p>
                        <p>Feedfoward 不同於 Attention 使用矩陣的線性變化，是用非線形變換，因為非線性變換的學習能力較線性變換強。它在每次變換時都引入非線性激活函數
                            Reul，將數據從高緯度的空間引入低緯度的空間，提取更深層的特徵。簡單來說，就是為 Attention 所得到的 values 來提取更仔細的內容。</p>
                    </div>
                    <div class="right">
                        <div class="image-container">
                            <img src="Transformer_flow.png" alt="Transformer 模型流程圖">
                            <p>Transformer 模型流程圖</p>
                        </div>
                        <div class="image-container">
                            <img src="Attention_flow.png" alt="Attention 流程圖">
                            <p>Attention 流程圖</p>
                        </div>
                    </div>
                </div>
            </section>
            <section id="example">
                <h3>Example</h3>
                <hr>
                <p>Grover 從 Google 新聞上5,000個不同媒體撰寫的新聞中進行學習。為提升假新聞辨識準確度，運用到生成對抗網路（GAN）技術，在此技術的運作下，最終 Grover 分辨人和 AI
                    寫的故事的正確率是92%。在此之前，最好的假新聞辨識器的正確率是73%。</p>
                <div class="container">
                    <div class="left">
                        <h4>限制</h4>
                        <p>Grover 仍有8%的假新聞無法分辨。</p>
                        <h4>可能解法</h4>
                        <p>提供更多樣本，並加強訓練時間，以提高 AI 的辨識率。</p>
                        <h4>風險</h4>
                        <p>Grover 在 GAN 技術的運作下，除了訓練出辨認假訊息的 AI 外，還訓練了生成假新聞的 AI ，若後者被有心人所利用，將對現今的資訊社會產生風險。</p>
                        <button onclick="window.open('https://grover.allenai.org/', '_blank')">前往 Grover</button>
                    </div>
                    <div class="right">
                        <div class="image-container">
                            <img src="GAN_flow.png" alt="生成對抗網路（GAN）的架構">
                            <p>生成對抗網路（GAN）的架構</p>
                        </div>
                    </div>
                </div>
            </section>
            <hr class="bottom">
            <section id="reference">
                <h5>Reference</h5>
                <p><a href="https://www.ifanr.com/1249217">https://www.ifanr.com/1249217</a>
                    <br><a
                        href="https://lawjournal.nuk.edu.tw/attach/1802-2.pdf">https://lawjournal.nuk.edu.tw/attach/1802-2.pdf</a>
                    <br><a
                        href="https://www.netadmin.com.tw/netadmin/zh-tw/technology/413C79020CA54C6E8ECAD1222A8B19FA">https://www.netadmin.com.tw/netadmin/zh-tw/technology/413C79020CA54C6E8ECAD1222A8B19FA</a>
                    <br><a
                        href="https://txt.cohere.com/what-are-transformer-models/">https://txt.cohere.com/what-are-transformer-models/</a>
                    <br><a
                        href="https://jalammar.github.io/illustrated-transformer/?ref=txt.cohere.com">https://jalammar.github.io/illustrated-transformer/?ref=txt.cohere.com</a>
                </p>
            </section>
            <section id="edit">
                <script>
                    document.write("Last Update: " + document.lastModified);
                </script>
            </section>
        </section>
    </main>
</body>

</html>